import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import pickle
from datetime import datetime

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ì‹¬í™” ë¶„ì„",
    page_icon="ğŸ“ˆ",
    layout="wide"
)

st.title("ğŸ“ˆ Step 4: ì‹¬í™” ë¶„ì„ ë° ì¸ì‚¬ì´íŠ¸")
st.markdown("### ëª¨ë¸ ì„±ëŠ¥ì„ ê¹Šì´ ìˆê²Œ ë¶„ì„í•˜ê³  ê°œì„  ë°©í–¥ì„ ì°¾ì•„ë´…ë‹ˆë‹¤")

# ë°ì´í„° ë° ëª¨ë¸ ì²´í¬
if 'data' not in st.session_state or st.session_state.data is None:
    st.error("âš ï¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„° ì¤€ë¹„ë¶€í„° ì‹œì‘í•´ì£¼ì„¸ìš”.")
    if st.button("ë°ì´í„° ì¤€ë¹„ í˜ì´ì§€ë¡œ ì´ë™"):
        st.switch_page("pages/1_ğŸ“Š_ë°ì´í„°_ì¤€ë¹„.py")
    st.stop()

if 'models' not in st.session_state or not st.session_state.models:
    st.warning("âš ï¸ í•™ìŠµëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ëª¨ë¸ì„ í•™ìŠµì‹œì¼œì£¼ì„¸ìš”.")
    if st.button("ëª¨ë¸ í•™ìŠµ í˜ì´ì§€ë¡œ ì´ë™"):
        st.switch_page("pages/3_ğŸ¤–_ëª¨ë¸_í•™ìŠµ.py")
    st.stop()

# êµìœ¡ ì½˜í…ì¸ 
with st.expander("ğŸ“š ì‹¬í™” ë¶„ì„ì˜ ì¤‘ìš”ì„±", expanded=True):
    st.markdown("""
    ### ğŸ¯ ì™œ ì‹¬í™” ë¶„ì„ì´ í•„ìš”í•œê°€?
    
    ë‹¨ìˆœí•œ ì •í™•ë„ ìˆ˜ì¹˜ë§Œìœ¼ë¡œëŠ” ëª¨ë¸ì˜ ì§„ì§œ ì„±ëŠ¥ì„ ì•Œ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
    
    **ì‹¬í™” ë¶„ì„ì„ í†µí•´ ì•Œ ìˆ˜ ìˆëŠ” ê²ƒë“¤:**
    
    1. **ëª¨ë¸ì˜ ì•½ì **
       - ì–´ë–¤ ìƒí™©ì—ì„œ í‹€ë¦¬ëŠ”ê°€?
       - íŠ¹ì • í´ë˜ìŠ¤ë‚˜ ë²”ìœ„ì—ì„œ ì„±ëŠ¥ì´ ë–¨ì–´ì§€ëŠ”ê°€?
    
    2. **ê°œì„  ê°€ëŠ¥ì„±**
       - ë” ë§ì€ ë°ì´í„°ê°€ í•„ìš”í•œê°€?
       - ë‹¤ë¥¸ íŠ¹ì„±ì´ í•„ìš”í•œê°€?
       - ëª¨ë¸ ë³µì¡ë„ ì¡°ì •ì´ í•„ìš”í•œê°€?
    
    3. **ì‹¤ì œ ë°°í¬ ê°€ëŠ¥ì„±**
       - ì˜ˆì¸¡ì˜ ì‹ ë¢°ë„ëŠ” ì–´ëŠ ì •ë„ì¸ê°€?
       - ì˜¤ë¥˜ì˜ ë¹„ìš©ì€ ì–¼ë§ˆë‚˜ ë˜ëŠ”ê°€?
       - ì„¤ëª… ê°€ëŠ¥í•œ ì˜ˆì¸¡ì¸ê°€?
    
    4. **ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸**
       - ì–´ë–¤ ìš”ì¸ì´ ê°€ì¥ ì¤‘ìš”í•œê°€?
       - ì˜ˆìƒê³¼ ë‹¤ë¥¸ íŒ¨í„´ì´ ìˆëŠ”ê°€?
       - ì‹¤í–‰ ê°€ëŠ¥í•œ í†µì°°ì´ ìˆëŠ”ê°€?
    """)

st.divider()

# ë¶„ì„ íƒ­
tab1, tab2, tab3, tab4, tab5 = st.tabs([
    "ğŸ”¬ ì˜¤ë¥˜ ë¶„ì„",
    "ğŸ“Š í•™ìŠµ ê³¡ì„ ",
    "ğŸ² ì˜ˆì¸¡ ë¶ˆí™•ì‹¤ì„±",
    "ğŸ”„ êµì°¨ ê²€ì¦ ì‹¬í™”",
    "ğŸ’¡ ê°œì„  ì œì•ˆ"
])

# ë°ì´í„° ì¤€ë¹„
df = st.session_state.data.copy()
target_col = st.session_state.target_column
problem_type = st.session_state.data_type

with tab1:
    st.markdown("## ğŸ”¬ ì˜¤ë¥˜ ë¶„ì„ (Error Analysis)")
    st.markdown("ëª¨ë¸ì´ ì–´ë–¤ ê²½ìš°ì— í‹€ë¦¬ëŠ”ì§€ íŒ¨í„´ì„ ì°¾ì•„ë´…ë‹ˆë‹¤.")
    
    # ëª¨ë¸ ì„ íƒ
    model_name = st.selectbox(
        "ë¶„ì„í•  ëª¨ë¸",
        list(st.session_state.models.keys()),
        key="error_analysis_model"
    )
    
    if model_name:
        model_info = st.session_state.models[model_name]
        
        # ì˜ˆì¸¡ê°’ì´ ìˆëŠ”ì§€ í™•ì¸
        if 'y_pred' in model_info:
            y_pred = model_info['y_pred']
            
            # ì‹¤ì œ í…ŒìŠ¤íŠ¸ ë°ì´í„° í•„ìš” (ì¬ìƒì„±)
            from sklearn.model_selection import train_test_split
            from sklearn.preprocessing import StandardScaler, LabelEncoder
            
            X = df.drop(columns=[target_col])
            y = df[target_col]
            
            if problem_type == 'classification' and y.dtype == 'object':
                le = LabelEncoder()
                y = le.fit_transform(y)
            
            numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()
            X = X[numeric_cols]
            
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=0.2, random_state=42,
                stratify=y if problem_type == 'classification' else None
            )
            
            if problem_type == 'classification':
                st.markdown("### ğŸ¯ ë¶„ë¥˜ ì˜¤ë¥˜ ë¶„ì„")
                
                # ì˜¤ë¶„ë¥˜ ìƒ˜í”Œ ì°¾ê¸°
                misclassified_mask = y_test != y_pred
                misclassified_indices = np.where(misclassified_mask)[0]
                
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.metric("ì „ì²´ í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ", len(y_test))
                with col2:
                    st.metric("ì˜¤ë¶„ë¥˜ ìƒ˜í”Œ", len(misclassified_indices))
                with col3:
                    st.metric("ì˜¤ë¥˜ìœ¨", f"{len(misclassified_indices)/len(y_test)*100:.1f}%")
                
                if len(misclassified_indices) > 0:
                    # ì˜¤ë¶„ë¥˜ íŒ¨í„´ ë¶„ì„
                    st.markdown("#### ì˜¤ë¶„ë¥˜ íŒ¨í„´")
                    
                    misclass_df = pd.DataFrame({
                        'ì‹¤ì œ': y_test[misclassified_mask],
                        'ì˜ˆì¸¡': y_pred[misclassified_mask]
                    })
                    
                    # ì˜¤ë¶„ë¥˜ ë§¤íŠ¸ë¦­ìŠ¤
                    confusion_pairs = misclass_df.groupby(['ì‹¤ì œ', 'ì˜ˆì¸¡']).size().reset_index(name='íšŸìˆ˜')
                    confusion_pairs = confusion_pairs.sort_values('íšŸìˆ˜', ascending=False)
                    
                    fig = px.bar(
                        confusion_pairs.head(10),
                        x='íšŸìˆ˜',
                        y=[f"{row['ì‹¤ì œ']} â†’ {row['ì˜ˆì¸¡']}" for _, row in confusion_pairs.head(10).iterrows()],
                        orientation='h',
                        title="ê°€ì¥ ë¹ˆë²ˆí•œ ì˜¤ë¶„ë¥˜ íŒ¨í„´ (ì‹¤ì œ â†’ ì˜ˆì¸¡)"
                    )
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # ì˜¤ë¶„ë¥˜ ìƒ˜í”Œì˜ íŠ¹ì„± ë¶„ì„
                    st.markdown("#### ì˜¤ë¶„ë¥˜ ìƒ˜í”Œì˜ íŠ¹ì„±")
                    
                    feature_to_analyze = st.selectbox(
                        "ë¶„ì„í•  íŠ¹ì„±",
                        numeric_cols
                    )
                    
                    if feature_to_analyze:
                        # ì •í™•/ì˜¤ë¶„ë¥˜ ìƒ˜í”Œì˜ íŠ¹ì„± ë¶„í¬ ë¹„êµ
                        fig = go.Figure()
                        
                        correct_values = X_test[~misclassified_mask][feature_to_analyze]
                        incorrect_values = X_test[misclassified_mask][feature_to_analyze]
                        
                        fig.add_trace(go.Box(
                            y=correct_values,
                            name="ì •í™•í•œ ì˜ˆì¸¡",
                            marker_color='green'
                        ))
                        
                        fig.add_trace(go.Box(
                            y=incorrect_values,
                            name="ì˜ëª»ëœ ì˜ˆì¸¡",
                            marker_color='red'
                        ))
                        
                        fig.update_layout(
                            title=f"{feature_to_analyze}ì˜ ë¶„í¬: ì •í™• vs ì˜¤ë¶„ë¥˜",
                            yaxis_title=feature_to_analyze
                        )
                        
                        st.plotly_chart(fig, use_container_width=True)
                        
                        # í†µê³„ì  ì°¨ì´
                        from scipy import stats
                        
                        if len(correct_values) > 0 and len(incorrect_values) > 0:
                            t_stat, p_value = stats.ttest_ind(correct_values, incorrect_values)
                            
                            if p_value < 0.05:
                                st.warning(f"âš ï¸ {feature_to_analyze}ì—ì„œ ì •í™•/ì˜¤ë¶„ë¥˜ ê·¸ë£¹ ê°„ ìœ ì˜ë¯¸í•œ ì°¨ì´ê°€ ìˆìŠµë‹ˆë‹¤ (p={p_value:.4f})")
                            else:
                                st.info(f"â„¹ï¸ {feature_to_analyze}ì—ì„œ ì •í™•/ì˜¤ë¶„ë¥˜ ê·¸ë£¹ ê°„ ìœ ì˜ë¯¸í•œ ì°¨ì´ê°€ ì—†ìŠµë‹ˆë‹¤ (p={p_value:.4f})")
            
            else:  # íšŒê·€
                st.markdown("### ğŸ“‰ íšŒê·€ ì˜¤ì°¨ ë¶„ì„")
                
                errors = np.abs(y_test - y_pred)
                
                # ì˜¤ì°¨ ë¶„í¬
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.metric("í‰ê·  ì ˆëŒ€ ì˜¤ì°¨", f"{errors.mean():.3f}")
                with col2:
                    st.metric("ìµœëŒ€ ì˜¤ì°¨", f"{errors.max():.3f}")
                with col3:
                    st.metric("ì˜¤ì°¨ í‘œì¤€í¸ì°¨", f"{errors.std():.3f}")
                
                # í° ì˜¤ì°¨ ìƒ˜í”Œ ë¶„ì„
                threshold = st.slider(
                    "í° ì˜¤ì°¨ ê¸°ì¤€ (ìƒìœ„ %)",
                    5, 30, 10
                )
                
                error_threshold = np.percentile(errors, 100 - threshold)
                large_error_mask = errors > error_threshold
                
                st.markdown(f"#### ìƒìœ„ {threshold}% ì˜¤ì°¨ ìƒ˜í”Œ ë¶„ì„")
                
                # íŠ¹ì„±ë³„ ë¶„ì„
                feature_to_analyze = st.selectbox(
                    "ë¶„ì„í•  íŠ¹ì„±",
                    numeric_cols,
                    key="regression_error_feature"
                )
                
                if feature_to_analyze:
                    fig = go.Figure()
                    
                    fig.add_trace(go.Scatter(
                        x=X_test[feature_to_analyze],
                        y=errors,
                        mode='markers',
                        marker=dict(
                            color=large_error_mask,
                            colorscale=['blue', 'red'],
                            size=8,
                            opacity=0.6
                        ),
                        text=[f"ì˜¤ì°¨: {e:.2f}" for e in errors],
                        name="ì˜¤ì°¨"
                    ))
                    
                    fig.add_hline(
                        y=error_threshold,
                        line_dash="dash",
                        line_color="red",
                        annotation_text=f"ìƒìœ„ {threshold}% ê¸°ì¤€ì„ "
                    )
                    
                    fig.update_layout(
                        title=f"{feature_to_analyze} vs ì˜ˆì¸¡ ì˜¤ì°¨",
                        xaxis_title=feature_to_analyze,
                        yaxis_title="ì ˆëŒ€ ì˜¤ì°¨"
                    )
                    
                    st.plotly_chart(fig, use_container_width=True)

with tab2:
    st.markdown("## ğŸ“Š í•™ìŠµ ê³¡ì„  ë¶„ì„")
    st.markdown("ë°ì´í„° í¬ê¸°ì™€ ëª¨ë¸ ë³µì¡ë„ê°€ ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë¶„ì„í•©ë‹ˆë‹¤.")
    
    analysis_type = st.radio(
        "ë¶„ì„ ìœ í˜•",
        ["í•™ìŠµ ë°ì´í„° í¬ê¸°", "ëª¨ë¸ ë³µì¡ë„"]
    )
    
    if analysis_type == "í•™ìŠµ ë°ì´í„° í¬ê¸°":
        st.markdown("### ğŸ“ˆ í•™ìŠµ ê³¡ì„  (Learning Curve)")
        st.info("ë°ì´í„°ê°€ ë” ë§ìœ¼ë©´ ì„±ëŠ¥ì´ í–¥ìƒë ê¹Œìš”?")
        
        selected_model = st.selectbox(
            "ë¶„ì„í•  ëª¨ë¸",
            list(st.session_state.models.keys()),
            key="learning_curve_model"
        )
        
        if st.button("í•™ìŠµ ê³¡ì„  ìƒì„±"):
            with st.spinner("í•™ìŠµ ê³¡ì„  ìƒì„± ì¤‘..."):
                from sklearn.model_selection import learning_curve
                
                model = st.session_state.models[selected_model]['model']
                
                # í•™ìŠµ ê³¡ì„  ê³„ì‚°
                train_sizes = np.linspace(0.1, 1.0, 10)
                
                train_sizes_abs, train_scores, val_scores = learning_curve(
                    model.__class__(),  # ìƒˆ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
                    X_train, y_train,
                    train_sizes=train_sizes,
                    cv=5,
                    scoring='accuracy' if problem_type == 'classification' else 'r2',
                    n_jobs=-1
                )
                
                # í‰ê· ê³¼ í‘œì¤€í¸ì°¨
                train_mean = train_scores.mean(axis=1)
                train_std = train_scores.std(axis=1)
                val_mean = val_scores.mean(axis=1)
                val_std = val_scores.std(axis=1)
                
                # ì‹œê°í™”
                fig = go.Figure()
                
                # í›ˆë ¨ ì ìˆ˜
                fig.add_trace(go.Scatter(
                    x=train_sizes_abs,
                    y=train_mean,
                    mode='lines+markers',
                    name='í›ˆë ¨ ì ìˆ˜',
                    line=dict(color='blue'),
                    error_y=dict(
                        type='data',
                        array=train_std,
                        visible=True
                    )
                ))
                
                # ê²€ì¦ ì ìˆ˜
                fig.add_trace(go.Scatter(
                    x=train_sizes_abs,
                    y=val_mean,
                    mode='lines+markers',
                    name='ê²€ì¦ ì ìˆ˜',
                    line=dict(color='red'),
                    error_y=dict(
                        type='data',
                        array=val_std,
                        visible=True
                    )
                ))
                
                fig.update_layout(
                    title="í•™ìŠµ ê³¡ì„ : ë°ì´í„° í¬ê¸°ì— ë”°ë¥¸ ì„±ëŠ¥",
                    xaxis_title="í›ˆë ¨ ë°ì´í„° í¬ê¸°",
                    yaxis_title="ì ìˆ˜",
                    hovermode='x unified'
                )
                
                st.plotly_chart(fig, use_container_width=True)
                
                # í•´ì„
                gap = train_mean[-1] - val_mean[-1]
                
                if gap > 0.1:
                    st.warning("""
                    âš ï¸ **ê³¼ì í•© ì§•í›„**
                    - í›ˆë ¨ê³¼ ê²€ì¦ ì ìˆ˜ ì°¨ì´ê°€ í½ë‹ˆë‹¤
                    - í•´ê²°ì±…: ì •ê·œí™” ê°•í™”, ë” ë§ì€ ë°ì´í„°, ëª¨ë¸ ë‹¨ìˆœí™”
                    """)
                elif val_mean[-1] < 0.7:
                    st.warning("""
                    âš ï¸ **ê³¼ì†Œì í•© ì§•í›„**
                    - ì „ë°˜ì ìœ¼ë¡œ ì„±ëŠ¥ì´ ë‚®ìŠµë‹ˆë‹¤
                    - í•´ê²°ì±…: ëª¨ë¸ ë³µì¡ë„ ì¦
